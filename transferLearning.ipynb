{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sampleSubmission.csv', 'test1', 'train']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "print(os.listdir(\"input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 14,731,074\n",
      "Trainable params: 14,731,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(VGG16(include_top=False, input_shape=(128,128,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False, input_shape=(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers[:-4]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, False),\n",
       " (InputSpec(ndim=4, axes={-1: 3}), False),\n",
       " (InputSpec(ndim=4, axes={-1: 64}), False),\n",
       " (InputSpec(ndim=4), False),\n",
       " (InputSpec(ndim=4, axes={-1: 64}), False),\n",
       " (InputSpec(ndim=4, axes={-1: 128}), False),\n",
       " (InputSpec(ndim=4), False),\n",
       " (InputSpec(ndim=4, axes={-1: 128}), False),\n",
       " (InputSpec(ndim=4, axes={-1: 256}), False),\n",
       " (InputSpec(ndim=4, axes={-1: 256}), False),\n",
       " (InputSpec(ndim=4), False),\n",
       " (InputSpec(ndim=4, axes={-1: 256}), False),\n",
       " (InputSpec(ndim=4, axes={-1: 512}), False),\n",
       " (InputSpec(ndim=4, axes={-1: 512}), False),\n",
       " (InputSpec(ndim=4), False),\n",
       " (InputSpec(ndim=4, axes={-1: 512}), True),\n",
       " (InputSpec(ndim=4, axes={-1: 512}), True),\n",
       " (InputSpec(ndim=4, axes={-1: 512}), True),\n",
       " (InputSpec(ndim=4), True)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.input_spec, x.trainable) for x in vgg.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 14,731,074\n",
      "Trainable params: 14,731,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"input/train\")\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':                                                                                                             categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize image parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_RUN = False\n",
    "IMAGE_WIDTH=128\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe1e22747f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'})\n",
    "train_df, validate_df = train_test_split(df, test_size=0.10, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 validated image filenames belonging to 2 classes.\n",
      "Found 2500 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# # Traning Generator                                                                                                         \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,                                                                                                         width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")   \n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,                                                                                                                     \"input/train/\",                                                                                                               x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',    \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df,                                                                                                                  \"input/train/\",                                                                                                               x_col='filename',                                                                                                             y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From /home/afwebb/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "epochs=2 #if FAST_RUN else 50\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size\n",
    "    #callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
